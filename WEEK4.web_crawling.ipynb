{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🐣 [PYTHON] Web Crawling\n",
    "\n",
    "\n",
    "## 1. BeautifulSoup\n",
    "\n",
    "    * 웹페이지의 내용을 가져오는 모듈\n",
    "   \n",
    "   ### a. 텍스트 인덱싱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "page = open(\"C:\\\\Users\\\\Owner\\\\Documents\\\\DataScience\\\\03. test_first.html\", \"r\").read()\n",
    "soup = BeautifulSoup(page, 'html.parser') #객체 생성, Python’s html.parser - 문서 전체를 저장한 변수 \n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #### * `.prettify()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Very Simple HTML Code by PinkWink\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <p class=\"inner-text first-item\" id=\"first\">\n",
      "    Happy PinkWink.\n",
      "    <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">\n",
      "     PinkWink\n",
      "    </a>\n",
      "   </p>\n",
      "   <p class=\"inner-text second-item\">\n",
      "    Happy Data Science.\n",
      "    <a href=\"https://www.python.org\" id=\"py-link\">\n",
      "     Python\n",
      "    </a>\n",
      "   </p>\n",
      "  </div>\n",
      "  <p class=\"outer-text first-item\" id=\"second\">\n",
      "   <b>\n",
      "    Data Science is funny.\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"outer-text\">\n",
      "   <b>\n",
      "    All I need is Love.\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())  #태그 예쁘게~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>Very Simple HTML Code by PinkWink</title>\n",
       " </head>\n",
       " <body>\n",
       " <div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>\n",
       " </div>\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children) # soup에서 children 인 부분을 묶어서 리스트로 만들어주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html 변수를 선언하고 2번째 리스트 항목부터 담아준다. 그 안부터 html의 내용이 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Very Simple HTML Code by PinkWink</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = list(soup.children)[2]\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html의 자식들(안의 내용)을 다시 리스트로 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(html.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body=list(html.children)[3]\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**html 파일의 body만 뽑는 법**\n",
    "1. list로 선언해서 안의 내용부터 출력하기\n",
    "2. 변수명.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * `.find_all()` , `.find(첫번째 것만 반환)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_='outer-text') #css의 id 찾기도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * `.head`, ` .next_sibling()`\n",
    "    head는 html의 head 부분을 가져오고, next_sibling 함수를 통해 다음, 그 다음 태그까지 가져올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head>\n",
       "<title>Very Simple HTML Code by PinkWink</title>\n",
       "</head>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                Happy PinkWink.\n",
       "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       "</p>\n",
       "<p class=\"inner-text second-item\">\n",
       "                Happy Data Science.\n",
       "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       "</p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                Data Science is funny.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                All I need is Love.\n",
       "            </b>\n",
       "</p>\n",
       "</body>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. 텍스트 정보 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 Happy PinkWink.\n",
       "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
       " </p>,\n",
       " <p class=\"inner-text second-item\">\n",
       "                 Happy Data Science.\n",
       "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
       " </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 Data Science is funny.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 All I need is Love.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p') #type==list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * `.get_text()`, `.string' 텍스트만 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Happy PinkWink.\n",
      "                PinkWink\n",
      "\n",
      "\n",
      "                Happy Data Science.\n",
      "                Python\n",
      "\n",
      "\n",
      "\n",
      "                Data Science is funny.\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "                All I need is Love.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for each_tag in soup.find_all('p'): #리스트이기에 가능 \n",
    "    print(each_tag.get_text())  # 태그 안의 텍스트만 가져와라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>,\n",
       " <a href=\"https://www.python.org\" id=\"py-link\">Python</a>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PinkWink -> http://www.pinkwink.kr\n",
      "Python -> https://www.python.org\n"
     ]
    }
   ],
   "source": [
    "for each in links: \n",
    "    href = each['href'] #href만 가져와라 \n",
    "    text = each.string\n",
    "    print(text + ' -> ' + href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. urllib과 함께 웹 크롤링!\n",
    "\n",
    "### a. KOSPI\n",
    "    cf. **구글 크롬 개발자 도구**\n",
    "    단축키 F12\n",
    "    왼쪽 맨위 (Select Element in the page to inspect it) Click!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"num\" id=\"KOSPI_now\">1,836.21</span>, <span class=\"num\" id=\"KOSDAQ_now\">615.95</span>, <span class=\"num\" id=\"KPI200_now\">245.61</span>]\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = urlopen('https://finance.naver.com/sise/') # url 넣기\n",
    "soup = BeautifulSoup(res, \"html.parser\") # 객체 생성\n",
    "\n",
    "data = soup.find_all('span', class_='num') # 원하는 태크를 이용해 찾기\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"num\" id=\"KOSPI_now\">1,836.21</span>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kospi=data[0] #리스트니까 그냥 불러와!\n",
    "kospi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,836.21'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kospi.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. 뉴스기사 제목 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.hankookilbo.com/News/Society/HC01'\n",
    "page = urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\") #구글 개발자 도구를 이용해 내가 추출하고 싶은 데이터 알기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\">[클릭! 자치뉴스]</p>,\n",
       " <p class=\"title\">박사방 ‘부따’ 구속…법원 “범행수법 치밀하고 계획적”</p>,\n",
       " <p class=\"title\">채널A “취재윤리 위반 송구…지시는 없었다”</p>,\n",
       " <p class=\"title\">“코로나19로 함께 한 우리” 눈물... 보문동 1만6,000개 마스크 제작 ‘기적의 순간’</p>,\n",
       " <p class=\"title\">또래 여학생 집단 성폭행 남중생 2명 구속</p>,\n",
       " <p class=\"title\">교육부 “학원에서 학교 원격수업 들으면 불법”</p>,\n",
       " <p class=\"title\">계란 던지고 흉기 난동까지…폭력에 위협 당하는 총선</p>,\n",
       " <p class=\"title\">수능 대리 응시자 사진 달랐지만…감독관들 \"몰랐다\"</p>,\n",
       " <p class=\"title\">자가격리 기간 출근한 약사ㆍ약국 직원... 검찰, 불구속 기소</p>,\n",
       " <p class=\"title\">온라인 수업 20분만에 나온 아들 \"대화창 비속어로 수업 중단\"</p>,\n",
       " <p class=\"title\">\"대구 위해 밤낮 고생했는데…\" 받을 돈 못 받은 의료진·업체들</p>,\n",
       " <p class=\"title\">[영상] “선생님 소리 들려요?”... 조마조마 온라인 개학 첫날</p>,\n",
       " <p class=\"title\">“유흥업소 중심 ‘조용한 전파’ ㆍ재확진자 늘어 안심 못 한다”</p>,\n",
       " <p class=\"title\">삼성SDI 울산공장에 노조 설립… 한국노총 가입</p>,\n",
       " <p class=\"title\">강남구 “집에 있었다” 허위 진술 유흥업소 직원 고발</p>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = soup.find_all('p', class_='title')\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[클릭! 자치뉴스]\n",
      "박사방 ‘부따’ 구속…법원 “범행수법 치밀하고 계획적”\n",
      "채널A “취재윤리 위반 송구…지시는 없었다”\n",
      "“코로나19로 함께 한 우리” 눈물... 보문동 1만6,000개 마스크 제작 ‘기적의 순간’\n",
      "또래 여학생 집단 성폭행 남중생 2명 구속\n",
      "교육부 “학원에서 학교 원격수업 들으면 불법”\n",
      "계란 던지고 흉기 난동까지…폭력에 위협 당하는 총선\n",
      "수능 대리 응시자 사진 달랐지만…감독관들 \"몰랐다\"\n",
      "자가격리 기간 출근한 약사ㆍ약국 직원... 검찰, 불구속 기소\n",
      "온라인 수업 20분만에 나온 아들 \"대화창 비속어로 수업 중단\"\n",
      "\"대구 위해 밤낮 고생했는데…\" 받을 돈 못 받은 의료진·업체들\n",
      "[영상] “선생님 소리 들려요?”... 조마조마 온라인 개학 첫날\n",
      "“유흥업소 중심 ‘조용한 전파’ ㆍ재확진자 늘어 안심 못 한다”\n",
      "삼성SDI 울산공장에 노조 설립… 한국노총 가입\n",
      "강남구 “집에 있었다” 허위 진술 유흥업소 직원 고발\n"
     ]
    }
   ],
   "source": [
    "title_list = []\n",
    "\n",
    "for title in titles: \n",
    "    title_list.append(title.get_text())\n",
    "    \n",
    "for title in title_list: \n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. openpyxl 로 크롤링한 데이터 저장, 읽기\n",
    "\n",
    "* 엑셀에 담아서 저장하고 읽을 수 있다.\n",
    "    ### a. 엑셀파일에 자료 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "excel_file = openpyxl.Workbook()\n",
    "excel_file.remove(excel_file.active)\n",
    "excel_sheet = excel_file.create_sheet('안녕 시트')  # sheet 이름 작성 \n",
    "\n",
    "excel_sheet.column_dimensions['B'].width = 150 # column B 크기 정하기 \n",
    "\n",
    "for index in range(9):\n",
    "    excel_sheet.append([index, '안녕']) # index number, 안녕 내용이 짝을 이뤄 9개\n",
    "\n",
    "cell_A1 = excel_sheet['A1']\n",
    "cell_A1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")\n",
    "\n",
    "excel_file.save('test.xlsx')  # 엑셀 파일 이름 설정\n",
    "excel_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "excel_file = openpyxl.Workbook()\n",
    "excel_file.remove(excel_file.active)\n",
    "excel_sheet = excel_file.create_sheet('사회뉴스')  # sheet 이름 작성 \n",
    "excel_sheet.column_dimensions['B'].width = 100   # 컬럼 크기 정하기 \n",
    "\n",
    "excel_sheet.append(['번호','제목']) #sheet에 표제목 넣기 \n",
    " \n",
    "url = 'https://www.hankookilbo.com/News/Society/HC01?Page=1'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "num = 0\n",
    "titles = soup.find_all('p', class_='title')   # 각 타이틀에서 p 중 class가 title인 것 가져오기 \n",
    "for title in titles: \n",
    "    # print(title.get_text())\n",
    "    num += 1\n",
    "    excel_sheet.append([num, title.get_text()])  # 타이틀 개수와 타이틀 내용 \n",
    "\n",
    "cell_A1 = excel_sheet['A1']\n",
    "cell_A1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")  # A1 양식 center로!\n",
    "cell_B1 = excel_sheet['B1']\n",
    "cell_B1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")  # B1 양식 center로!\n",
    "\n",
    "excel_file.save('한국일보 사회뉴스 타이틀 크롤링.xlsx')\n",
    "excel_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### b. 엑셀 파일 자료 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번호 제목\n",
      "1 [클릭! 자치뉴스]\n",
      "2 박사방 부따 구속…법원 “범행수법 치밀하고 계획적”\n",
      "3 채널A “취재윤리 위반 송구…지시는 없었다”\n",
      "4 “코로나19로 함께 한 우리” 눈물... 보문동 1만6,000개 마스크 제작 ‘기적의 순간’\n",
      "5 또래 여학생 집단 성폭행 남중생 2명 구속\n",
      "6 교육부 “학원에서 학교 원격수업 들으면 불법”\n",
      "7 계란 던지고 흉기 난동까지…폭력에 위협 당하는 총선\n",
      "8 수능 대리 응시자 사진 달랐지만…감독관들 \"몰랐다\"\n",
      "9 자가격리 기간 출근한 약사ㆍ약국 직원... 검찰, 불구속 기소\n",
      "10 온라인 수업 20분만에 나온 아들 \"대화창 비속어로 수업 중단\"\n",
      "11 \"대구 위해 밤낮 고생했는데…\" 받을 돈 못 받은 의료진·업체들\n",
      "12 [영상] “선생님 소리 들려요?”... 조마조마 온라인 개학 첫날\n",
      "13 “유흥업소 중심 ‘조용한 전파’ ㆍ재확진자 늘어 안심 못 한다”\n",
      "14 삼성SDI 울산공장에 노조 설립… 한국노총 가입\n",
      "15 강남구 “집에 있었다” 허위 진술 유흥업소 직원 고발\n"
     ]
    }
   ],
   "source": [
    "# 크롤링 데이터 엑셀 파일 읽기 \n",
    "import openpyxl\n",
    "\n",
    "excel_file = openpyxl.load_workbook('한국일보 사회뉴스 타이틀 크롤링.xlsx')\n",
    "excel_sheet = excel_file.active\n",
    "# excel_sheet = excel_file.get_sheet_by_name('사회뉴스') - 여러개 시트가 있을 때\n",
    "\n",
    "for row in excel_sheet.rows:\n",
    "    print(row[0].value, row[1].value)  # row의 첫번째, 두번째 칼럼 추출\n",
    "\n",
    "excel_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
